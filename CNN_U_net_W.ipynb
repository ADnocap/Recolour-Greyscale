{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Image Colorization — Baseline CNN (STL-10, 96×96)\n",
    "\n",
    "This notebook implements a **baseline encoder–decoder CNN** for **automatic image colorization** on the **STL-10 dataset**.  \n",
    "The task is formulated as a supervised regression problem:\n",
    "\n",
    "- **Input:** grayscale image `L` (1 channel, 96×96)\n",
    "- **Target:** RGB color image (3 channels, 96×96)\n",
    "\n",
    "## 1) Dataset pipeline (STL10GrayColor)\n",
    "We build a custom `Dataset` that returns `(gray, color)` pairs:\n",
    "- Load STL-10 RGB images\n",
    "- (Train only) apply **random horizontal flip**\n",
    "- Resize to **96×96**\n",
    "- Convert to:\n",
    "  - grayscale tensor `[1, H, W]` in `[0,1]`\n",
    "  - RGB tensor `[3, H, W]` in `[0,1]`\n",
    "\n",
    "## 2) Model: CNN Encoder–Decoder (96×96)\n",
    "The network is a standard **bottleneck architecture**:\n",
    "- **Encoder:** conv blocks + max pooling  \n",
    "  `1×96×96 → 64×48×48 → 128×24×24 → 256×12×12 → 512×6×6`\n",
    "- **Decoder:** transposed convolutions (upsampling) back to 96×96  \n",
    "  `512×6×6 → ... → 3×96×96`\n",
    "- Final `Sigmoid` ensures predictions stay in `[0,1]`.\n",
    "\n",
    "## 3) Training & evaluation\n",
    "- **Loss:** Mean Squared Error (**MSE**) on RGB pixels\n",
    "- **Optimizer:** Adam\n",
    "- **Metric:** **PSNR**, computed from the validation MSE:\n",
    "  \\[\n",
    "  \\mathrm{PSNR} = 10 \\log_{10}\\left(\\frac{1}{\\mathrm{MSE}}\\right)\n",
    "  \\]\n",
    "  (assuming images are normalized in `[0,1]`)\n",
    "\n",
    "We also provide visualization utilities:\n",
    "- training curves (MSE + PSNR)\n",
    "- qualitative results: **top-k best predictions** (lowest per-image MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Automatic Image Colorization (CNN Encoder–Decoder, STL-10 96x96)\n",
    "# ============================================================\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import STL10\n",
    "\n",
    "\n",
    "os.makedirs(\"resultsSTL\", exist_ok=True)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) Dataset: grayscale input -> RGB target\n",
    "# ============================================================\n",
    "class STL10GrayColor(Dataset):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        gray:  Tensor [1, H, W] in [0, 1]\n",
    "        color: Tensor [3, H, W] in [0, 1]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root: str = \"./data\", split: str = \"train\", download: bool = True, image_size: int = 96):\n",
    "        self.base = STL10(root=root, split=split, download=download)\n",
    "        self.split = split\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.resize_color = transforms.Resize((image_size, image_size))\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "        self.gray_transform = transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        self.augment = transforms.RandomHorizontalFlip(p=0.5) if split == \"train\" else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, _ = self.base[idx]  # PIL RGB image (label not used)\n",
    "\n",
    "        if self.augment is not None:\n",
    "            img = self.augment(img)\n",
    "\n",
    "        img = self.resize_color(img)\n",
    "\n",
    "        color = self.to_tensor(img)\n",
    "        gray = self.gray_transform(img)\n",
    "        return gray, color\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) CNN Encoder–Decoder for 96x96\n",
    "# ============================================================\n",
    "class ColorizationCNN96(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 96 -> 48\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 48 -> 24\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 24 -> 12\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 12 -> 6\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),  # 6 -> 12\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),  # 12 -> 24\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),   # 24 -> 48\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),    # 48 -> 96\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(32, 3, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid(),  # outputs in [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) Training / evaluation utilities\n",
    "# ============================================================\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n_samples = 0\n",
    "\n",
    "    for gray, color in dataloader:\n",
    "        gray = gray.to(device)\n",
    "        color = color.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(gray)\n",
    "        loss = criterion(pred, color)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        bs = gray.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        n_samples += bs\n",
    "\n",
    "    return total_loss / n_samples\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, eps: float = 1e-12):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    n_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for gray, color in dataloader:\n",
    "            gray = gray.to(device)\n",
    "            color = color.to(device)\n",
    "\n",
    "            pred = model(gray)\n",
    "            loss = criterion(pred, color)\n",
    "\n",
    "            bs = gray.size(0)\n",
    "            total_loss += loss.item() * bs\n",
    "            n_samples += bs\n",
    "\n",
    "    mse = total_loss / n_samples\n",
    "    mse_safe = max(mse, eps)\n",
    "    psnr = 10 * math.log10(1.0 / mse_safe)\n",
    "    return mse, psnr\n",
    "\n",
    "\n",
    "def show_samples(model, dataloader, device, n=5):\n",
    "    model.eval()\n",
    "    gray, color = next(iter(dataloader))\n",
    "    gray = gray.to(device)\n",
    "    color = color.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(gray)\n",
    "\n",
    "    gray = gray[:n].cpu()\n",
    "    color = color[:n].cpu()\n",
    "    pred = pred[:n].cpu()\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=n, ncols=3, figsize=(9, 3 * n))\n",
    "    if n == 1:\n",
    "        axes = np.expand_dims(axes, axis=0)\n",
    "\n",
    "    for i in range(n):\n",
    "        g = gray[i].squeeze(0).numpy()\n",
    "        gt = np.transpose(color[i].numpy(), (1, 2, 0))\n",
    "        pr = np.transpose(pred[i].numpy(), (1, 2, 0))\n",
    "\n",
    "        axes[i, 0].imshow(g, cmap=\"gray\")\n",
    "        axes[i, 0].set_title(\"Input (grayscale)\")\n",
    "        axes[i, 0].axis(\"off\")\n",
    "\n",
    "        axes[i, 1].imshow(pr)\n",
    "        axes[i, 1].set_title(\"Prediction\")\n",
    "        axes[i, 1].axis(\"off\")\n",
    "\n",
    "        axes[i, 2].imshow(gt)\n",
    "        axes[i, 2].set_title(\"Ground truth\")\n",
    "        axes[i, 2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) Ranking best samples by per-image MSE\n",
    "# ============================================================\n",
    "def get_top_k_samples(model, dataloader, device, k=10):\n",
    "    model.eval()\n",
    "    all_errors, all_gray, all_color, all_pred = [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for gray, color in dataloader:\n",
    "            gray = gray.to(device)\n",
    "            color = color.to(device)\n",
    "\n",
    "            pred = model(gray)\n",
    "            err = ((pred - color) ** 2).view(gray.size(0), -1).mean(dim=1)\n",
    "\n",
    "            all_errors.append(err.cpu())\n",
    "            all_gray.append(gray.cpu())\n",
    "            all_color.append(color.cpu())\n",
    "            all_pred.append(pred.cpu())\n",
    "\n",
    "    errors = torch.cat(all_errors)\n",
    "    gray_all = torch.cat(all_gray)\n",
    "    color_all = torch.cat(all_color)\n",
    "    pred_all = torch.cat(all_pred)\n",
    "\n",
    "    _, indices = torch.sort(errors)\n",
    "    topk_idx = indices[:k]\n",
    "\n",
    "    return gray_all[topk_idx], pred_all[topk_idx], color_all[topk_idx], errors[topk_idx]\n",
    "\n",
    "\n",
    "def show_top_k_samples(model, dataloader, device, k=10, filename=\"resultsSTL/topk_best_colorization.png\"):\n",
    "    gray_k, pred_k, color_k, err_k = get_top_k_samples(model, dataloader, device, k=k)\n",
    "\n",
    "    n = gray_k.size(0)\n",
    "    fig, axes = plt.subplots(nrows=n, ncols=3, figsize=(9, 3 * n))\n",
    "    if n == 1:\n",
    "        axes = np.expand_dims(axes, axis=0)\n",
    "\n",
    "    for i in range(n):\n",
    "        g = gray_k[i].squeeze(0).numpy()\n",
    "        gt = np.transpose(color_k[i].numpy(), (1, 2, 0))\n",
    "        pr = np.transpose(pred_k[i].numpy(), (1, 2, 0))\n",
    "\n",
    "        axes[i, 0].imshow(g, cmap=\"gray\")\n",
    "        axes[i, 0].set_title(\"Input (grayscale)\")\n",
    "        axes[i, 0].axis(\"off\")\n",
    "\n",
    "        axes[i, 1].imshow(pr)\n",
    "        axes[i, 1].set_title(f\"Prediction\\nMSE={err_k[i]:.4f}\")\n",
    "        axes[i, 1].axis(\"off\")\n",
    "\n",
    "        axes[i, 2].imshow(gt)\n",
    "        axes[i, 2].set_title(\"Ground truth\")\n",
    "        axes[i, 2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(filename, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5) Main\n",
    "# ============================================================\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    train_dataset = STL10GrayColor(split=\"train\", download=True, image_size=96)\n",
    "    test_dataset = STL10GrayColor(split=\"test\", download=True, image_size=96)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "    model = ColorizationCNN96().to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    num_epochs = 25\n",
    "    train_losses, val_losses, val_psnrs = [], [], []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_psnr = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_psnrs.append(val_psnr)\n",
    "\n",
    "        print(\n",
    "            f\"[Epoch {epoch:02d}/{num_epochs}] \"\n",
    "            f\"Train MSE: {train_loss:.4f} | Val MSE: {val_loss:.4f} | Val PSNR: {val_psnr:.2f} dB\"\n",
    "        )\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label=\"Train MSE\")\n",
    "    plt.plot(val_losses, label=\"Val MSE\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.title(\"Training / Validation Loss (STL-10, 96x96)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_psnrs, label=\"Val PSNR (dB)\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"PSNR (dB)\")\n",
    "    plt.title(\"Validation PSNR (STL-10, 96x96)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    show_top_k_samples(model, test_loader, device, k=50, filename=\"resultsSTL/top50_best_colorization.png\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Image Colorization — U-Net (STL-10, 96×96)\n",
    "\n",
    "This section upgrades the baseline encoder–decoder to a **U-Net** for colorization at **96×96**.  \n",
    "The key change is the use of **skip connections**: encoder feature maps are concatenated with decoder features at matching resolutions, helping preserve **edges and fine textures** that are typically lost through the bottleneck.\n",
    "\n",
    "## Model: ColorizationUNet96\n",
    "- **Encoder:** 4 downsampling stages (conv blocks + max pool)\n",
    "- **Bottleneck:** conv block at 6×6\n",
    "- **Decoder:** transposed convolutions + **concat skips** + conv blocks\n",
    "- Output head predicts **RGB** in `[0,1]` via `Sigmoid`.\n",
    "\n",
    "## Training objective\n",
    "We train with a **mixed regression loss** to reduce color averaging:\n",
    "- **Train loss:** weighted combination of **L1 + MSE**\n",
    "- **Evaluation:** PSNR is computed from **MSE only** on the validation/test set (pixel fidelity metric)\n",
    "\n",
    "## Outputs\n",
    "As in the baseline section, we log:\n",
    "- training curves (loss + PSNR)\n",
    "- qualitative examples (top-k lowest per-image MSE), saved under `resultsSTL_UNET/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Automatic Image Colorization (U-Net, STL-10 96x96)\n",
    "# ============================================================\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import STL10\n",
    "\n",
    "\n",
    "os.makedirs(\"resultsSTL_UNET\", exist_ok=True)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) Dataset: grayscale input -> RGB target\n",
    "# ============================================================\n",
    "class STL10GrayColor(Dataset):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        gray:  Tensor [1, H, W] in [0, 1]\n",
    "        color: Tensor [3, H, W] in [0, 1]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root: str = \"./data\", split: str = \"train\", download: bool = True, image_size: int = 96):\n",
    "        self.base = STL10(root=root, split=split, download=download)\n",
    "        self.split = split\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.resize_color = transforms.Resize((image_size, image_size))\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "        self.gray_transform = transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        self.augment = transforms.RandomHorizontalFlip(p=0.5) if split == \"train\" else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, _ = self.base[idx]  # PIL RGB image (label not used)\n",
    "\n",
    "        if self.augment is not None:\n",
    "            img = self.augment(img)\n",
    "\n",
    "        img = self.resize_color(img)\n",
    "\n",
    "        color = self.to_tensor(img)\n",
    "        gray = self.gray_transform(img)\n",
    "        return gray, color\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) U-Net model for 96x96 colorization\n",
    "# ============================================================\n",
    "def conv_block(in_ch, out_ch):\n",
    "    \"\"\"Two 3x3 convs + BN + ReLU (standard U-Net block).\"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(out_ch),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(out_ch),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "\n",
    "class ColorizationUNet96(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = conv_block(1, 64)\n",
    "        self.pool1 = nn.MaxPool2d(2)  # 96 -> 48\n",
    "\n",
    "        self.enc2 = conv_block(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(2)  # 48 -> 24\n",
    "\n",
    "        self.enc3 = conv_block(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)  # 24 -> 12\n",
    "\n",
    "        self.enc4 = conv_block(256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(2)  # 12 -> 6\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = conv_block(512, 512)  # 6x6\n",
    "\n",
    "        # Decoder + skip connections\n",
    "        self.up4 = nn.ConvTranspose2d(512, 512, kernel_size=4, stride=2, padding=1)  # 6 -> 12\n",
    "        self.dec4 = conv_block(512 + 512, 512)  # concat with enc4\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1)  # 12 -> 24\n",
    "        self.dec3 = conv_block(256 + 256, 256)  # concat with enc3\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1)  # 24 -> 48\n",
    "        self.dec2 = conv_block(128 + 128, 128)  # concat with enc2\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)   # 48 -> 96\n",
    "        self.dec1 = conv_block(64 + 64, 64)  # concat with enc1\n",
    "\n",
    "        self.final_conv = nn.Conv2d(64, 3, kernel_size=1)\n",
    "        self.final_act = nn.Sigmoid()  # outputs in [0, 1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        p1 = self.pool1(e1)\n",
    "\n",
    "        e2 = self.enc2(p1)\n",
    "        p2 = self.pool2(e2)\n",
    "\n",
    "        e3 = self.enc3(p2)\n",
    "        p3 = self.pool3(e3)\n",
    "\n",
    "        e4 = self.enc4(p3)\n",
    "        p4 = self.pool4(e4)\n",
    "\n",
    "        b = self.bottleneck(p4)\n",
    "\n",
    "        u4 = self.up4(b)\n",
    "        d4 = self.dec4(torch.cat([u4, e4], dim=1))\n",
    "\n",
    "        u3 = self.up3(d4)\n",
    "        d3 = self.dec3(torch.cat([u3, e3], dim=1))\n",
    "\n",
    "        u2 = self.up2(d3)\n",
    "        d2 = self.dec2(torch.cat([u2, e2], dim=1))\n",
    "\n",
    "        u1 = self.up1(d2)\n",
    "        d1 = self.dec1(torch.cat([u1, e1], dim=1))\n",
    "\n",
    "        out = self.final_act(self.final_conv(d1))\n",
    "        return out\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) Training / evaluation utilities\n",
    "# ============================================================\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n_samples = 0\n",
    "\n",
    "    for gray, color in dataloader:\n",
    "        gray = gray.to(device)\n",
    "        color = color.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(gray)\n",
    "        loss = criterion(pred, color)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        bs = gray.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        n_samples += bs\n",
    "\n",
    "    return total_loss / n_samples\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, eps: float = 1e-12):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    n_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for gray, color in dataloader:\n",
    "            gray = gray.to(device)\n",
    "            color = color.to(device)\n",
    "\n",
    "            pred = model(gray)\n",
    "            loss = criterion(pred, color)\n",
    "\n",
    "            bs = gray.size(0)\n",
    "            total_loss += loss.item() * bs\n",
    "            n_samples += bs\n",
    "\n",
    "    mse = total_loss / n_samples\n",
    "    mse_safe = max(mse, eps)\n",
    "    psnr = 10 * math.log10(1.0 / mse_safe)\n",
    "    return mse, psnr\n",
    "\n",
    "\n",
    "def show_samples(model, dataloader, device, n=5):\n",
    "    model.eval()\n",
    "    gray, color = next(iter(dataloader))\n",
    "    gray = gray.to(device)\n",
    "    color = color.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(gray)\n",
    "\n",
    "    gray = gray[:n].cpu()\n",
    "    color = color[:n].cpu()\n",
    "    pred = pred[:n].cpu()\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=n, ncols=3, figsize=(9, 3 * n))\n",
    "    if n == 1:\n",
    "        axes = np.expand_dims(axes, axis=0)\n",
    "\n",
    "    for i in range(n):\n",
    "        g = gray[i].squeeze(0).numpy()\n",
    "        gt = np.transpose(color[i].numpy(), (1, 2, 0))\n",
    "        pr = np.transpose(pred[i].numpy(), (1, 2, 0))\n",
    "\n",
    "        axes[i, 0].imshow(g, cmap=\"gray\")\n",
    "        axes[i, 0].set_title(\"Input (grayscale)\")\n",
    "        axes[i, 0].axis(\"off\")\n",
    "\n",
    "        axes[i, 1].imshow(pr)\n",
    "        axes[i, 1].set_title(\"Prediction\")\n",
    "        axes[i, 1].axis(\"off\")\n",
    "\n",
    "        axes[i, 2].imshow(gt)\n",
    "        axes[i, 2].set_title(\"Ground truth\")\n",
    "        axes[i, 2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) Ranking best samples by per-image MSE\n",
    "# ============================================================\n",
    "def get_top_k_samples(model, dataloader, device, k=10):\n",
    "    model.eval()\n",
    "    all_errors, all_gray, all_color, all_pred = [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for gray, color in dataloader:\n",
    "            gray = gray.to(device)\n",
    "            color = color.to(device)\n",
    "\n",
    "            pred = model(gray)\n",
    "            err = ((pred - color) ** 2).view(gray.size(0), -1).mean(dim=1)\n",
    "\n",
    "            all_errors.append(err.cpu())\n",
    "            all_gray.append(gray.cpu())\n",
    "            all_color.append(color.cpu())\n",
    "            all_pred.append(pred.cpu())\n",
    "\n",
    "    errors = torch.cat(all_errors)\n",
    "    gray_all = torch.cat(all_gray)\n",
    "    color_all = torch.cat(all_color)\n",
    "    pred_all = torch.cat(all_pred)\n",
    "\n",
    "    _, indices = torch.sort(errors)\n",
    "    topk_idx = indices[:k]\n",
    "\n",
    "    return gray_all[topk_idx], pred_all[topk_idx], color_all[topk_idx], errors[topk_idx]\n",
    "\n",
    "\n",
    "def show_top_k_samples(model, dataloader, device, k=10, filename=\"resultsSTL_UNET/topk_best_colorization.png\"):\n",
    "    gray_k, pred_k, color_k, err_k = get_top_k_samples(model, dataloader, device, k=k)\n",
    "\n",
    "    n = gray_k.size(0)\n",
    "    fig, axes = plt.subplots(nrows=n, ncols=3, figsize=(9, 3 * n))\n",
    "    if n == 1:\n",
    "        axes = np.expand_dims(axes, axis=0)\n",
    "\n",
    "    for i in range(n):\n",
    "        g = gray_k[i].squeeze(0).numpy()\n",
    "        gt = np.transpose(color_k[i].numpy(), (1, 2, 0))\n",
    "        pr = np.transpose(pred_k[i].numpy(), (1, 2, 0))\n",
    "\n",
    "        axes[i, 0].imshow(g, cmap=\"gray\")\n",
    "        axes[i, 0].set_title(\"Input (grayscale)\")\n",
    "        axes[i, 0].axis(\"off\")\n",
    "\n",
    "        axes[i, 1].imshow(pr)\n",
    "        axes[i, 1].set_title(f\"Prediction\\nMSE={err_k[i]:.4f}\")\n",
    "        axes[i, 1].axis(\"off\")\n",
    "\n",
    "        axes[i, 2].imshow(gt)\n",
    "        axes[i, 2].set_title(\"Ground truth\")\n",
    "        axes[i, 2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(filename, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5) Main\n",
    "# ============================================================\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    train_dataset = STL10GrayColor(split=\"train\", download=True, image_size=96)\n",
    "    test_dataset = STL10GrayColor(split=\"test\", download=True, image_size=96)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "    model = ColorizationUNet96().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    l1_loss = nn.L1Loss()\n",
    "\n",
    "    def combined_loss(pred, target):\n",
    "        # Weighted combination: encourages sharper colors (L1) while keeping pixel fidelity (MSE)\n",
    "        return 0.7 * l1_loss(pred, target) + 0.3 * mse_loss(pred, target)\n",
    "\n",
    "    num_epochs = 20\n",
    "    train_losses, val_losses, val_psnrs = [], [], []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss = train_one_epoch(model, train_loader, combined_loss, optimizer, device)\n",
    "\n",
    "        # Validation: PSNR is computed from MSE, so evaluate with MSE on the val set\n",
    "        val_loss, val_psnr = evaluate(model, test_loader, mse_loss, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_psnrs.append(val_psnr)\n",
    "\n",
    "        print(\n",
    "            f\"[Epoch {epoch:02d}/{num_epochs}] \"\n",
    "            f\"Train loss: {train_loss:.4f} | Val MSE: {val_loss:.4f} | Val PSNR: {val_psnr:.2f} dB\"\n",
    "        )\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label=\"Train loss (combined)\")\n",
    "    plt.plot(val_losses, label=\"Val MSE\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training / Validation Loss (STL-10, 96x96)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_psnrs, label=\"Val PSNR (dB)\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"PSNR (dB)\")\n",
    "    plt.title(\"Validation PSNR (STL-10, 96x96)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    show_top_k_samples(model, test_loader, device, k=50, filename=\"resultsSTL_UNET/top50_best_colorization.png\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
