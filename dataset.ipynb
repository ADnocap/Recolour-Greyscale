{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51bbec0a",
   "metadata": {},
   "source": [
    "Get FREE API keys:\n",
    "- Pexels: https://www.pexels.com/api/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468d6a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from PIL import Image, ImageStat\n",
    "from io import BytesIO\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6affac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SIZE = 512\n",
    "TOTAL_IMAGES = 10000 \n",
    "TRAIN_SPLIT = 0.8\n",
    "SATURATION_THRESHOLD = 20 # Threshold (0-255). 0 is pure grey. 20 filters out B&W and very washed-out sepia.\n",
    "\n",
    "PEXELS_API_KEY = \"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f052032e",
   "metadata": {},
   "source": [
    "# Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fb9eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_crop_to_square(image, size=512):\n",
    "    \"\"\"Resize and center crop to exact square\"\"\"\n",
    "    width, height = image.size\n",
    "    \n",
    "    if width < height:\n",
    "        new_width = size\n",
    "        new_height = int(height * (size / width))\n",
    "    else:\n",
    "        new_height = size\n",
    "        new_width = int(width * (size / height))\n",
    "    \n",
    "    image = image.resize((new_width, new_height), Image.LANCZOS)\n",
    "    \n",
    "    left = (new_width - size) // 2\n",
    "    top = (new_height - size) // 2\n",
    "    image = image.crop((left, top, left + size, top + size))\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def is_greyscale(image, threshold=20):\n",
    "    \"\"\"\n",
    "    Converts image to HSV and checks if the average saturation \n",
    "    is below the threshold.\n",
    "    \"\"\"\n",
    "    # Convert to Hue, Saturation, Value space\n",
    "    hsv_img = image.convert('HSV')\n",
    "    \n",
    "    # Calculate the average value of the Saturation channel (index 1)\n",
    "    saturation = ImageStat.Stat(hsv_img).mean[1]\n",
    "    \n",
    "    # If average saturation is low, it's likely greyscale/B&W\n",
    "    return saturation < threshold\n",
    "\n",
    "def download_and_process(img_url, timeout=15):\n",
    "    \"\"\"Download, check color, and ensure RGB 512x512\"\"\"\n",
    "    try:\n",
    "        response = requests.get(img_url, timeout=timeout)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        \n",
    "        if is_greyscale(image, SATURATION_THRESHOLD):\n",
    "            return None, False\n",
    "\n",
    "        \n",
    "        # Convert to RGB\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        \n",
    "        # Resize to 512x512\n",
    "        image = resize_and_crop_to_square(image, TARGET_SIZE)\n",
    "        \n",
    "        return image, True\n",
    "    except Exception as e:\n",
    "        # print(f\"Debug error: {e}\") \n",
    "        return None, False\n",
    "\n",
    "def download_from_pexels(api_key, total_images, train_split):\n",
    "    print(\"\\nDownloading from Pexels...\")\n",
    "    \n",
    "    os.makedirs('dataset/train', exist_ok=True)\n",
    "    os.makedirs('dataset/val', exist_ok=True)\n",
    "    \n",
    "    headers = {'Authorization': api_key}\n",
    "    train_count = int(total_images * train_split)\n",
    "    \n",
    "    train_idx = 0\n",
    "    val_idx = 0\n",
    "    downloaded = 0\n",
    "    failed = 0\n",
    "    page = 1\n",
    "    per_page = 80\n",
    "    \n",
    "    with tqdm(total=total_images, desc=\"Downloading\") as pbar:\n",
    "        while downloaded < total_images:\n",
    "            try:\n",
    "                url = f'https://api.pexels.com/v1/curated?per_page={per_page}&page={page}'\n",
    "                response = requests.get(url, headers=headers, timeout=15)\n",
    "                response.raise_for_status()\n",
    "                data = response.json()\n",
    "                \n",
    "                if 'photos' not in data or len(data['photos']) == 0:\n",
    "                    break\n",
    "                \n",
    "                for photo in data['photos']:\n",
    "                    if downloaded >= total_images:\n",
    "                        break\n",
    "                    \n",
    "                    # Get large image\n",
    "                    img_url = photo['src']['large2x']\n",
    "                    image, success = download_and_process(img_url)\n",
    "                    \n",
    "                    if success:\n",
    "                        # Save\n",
    "                        if train_idx < train_count:\n",
    "                            filename = f'dataset/train/image_{train_idx + 1:06d}.jpg'\n",
    "                            train_idx += 1\n",
    "                        else:\n",
    "                            filename = f'dataset/val/val_{val_idx + 1:06d}.jpg'\n",
    "                            val_idx += 1\n",
    "                        \n",
    "                        image.save(filename, 'JPEG', quality=95)\n",
    "                        downloaded += 1\n",
    "                        pbar.update(1)\n",
    "                    else:\n",
    "                        failed += 1\n",
    "                    \n",
    "                    time.sleep(0.05)\n",
    "                \n",
    "                page += 1\n",
    "                time.sleep(1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\nâŒ Error: {e}\")\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "    \n",
    "    print_summary(downloaded, train_idx, val_idx, failed)\n",
    "\n",
    "\n",
    "def print_summary(downloaded, train_idx, val_idx, failed):\n",
    "    print(f\"  Downloaded: {downloaded} images (512x512 RGB)\")\n",
    "    print(f\"  Train: {train_idx} images\")\n",
    "    print(f\"  Val: {val_idx} images\")\n",
    "    print(f\"  Failed: {failed}\")\n",
    "\n",
    "def main():\n",
    "    if PEXELS_API_KEY:\n",
    "        download_from_pexels(PEXELS_API_KEY, TOTAL_IMAGES, TRAIN_SPLIT)\n",
    "    else:\n",
    "        print(\"No API key found!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b34c545",
   "metadata": {},
   "source": [
    "# Split into test/train\n",
    "Only need to run this if you exhausted the dataset and need to split the data from train to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2501211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "train_dir = Path('dataset/train')\n",
    "val_dir = Path('dataset/val')\n",
    "\n",
    "val_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "jpg_files = list(train_dir.glob('*.jpg'))\n",
    "\n",
    "print(f\"Total images in train folder: {len(jpg_files)}\")\n",
    "\n",
    "# Calculate number of files to move (15%)\n",
    "num_val = int(len(jpg_files) * 0.15)\n",
    "print(f\"Moving {num_val} images to validation folder ({num_val/len(jpg_files)*100:.1f}%)\")\n",
    "\n",
    "# Randomly select files to move\n",
    "files_to_move = random.sample(jpg_files, num_val)\n",
    "\n",
    "# Move the files\n",
    "for file_path in files_to_move:\n",
    "    destination = val_dir / file_path.name\n",
    "    shutil.move(str(file_path), str(destination))\n",
    "    \n",
    "print(f\"Train folder now has: {len(list(train_dir.glob('*.jpg')))} images\")\n",
    "print(f\"Validation folder now has: {len(list(val_dir.glob('*.jpg')))} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd2476b",
   "metadata": {},
   "source": [
    "# Rename files in each folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be318bd",
   "metadata": {},
   "source": [
    "If you've shuffle the data and want clean names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0d628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_images_in_folder(folder_path, prefix):\n",
    "    \"\"\"\n",
    "    Rename all .jpg images in a folder with a given prefix and zero-padded numbering.\n",
    "    \n",
    "    Args:\n",
    "        folder_path: Path to the folder containing images\n",
    "        prefix: Prefix for the new filenames (e.g., 'train_img' or 'val_img')\n",
    "    \"\"\"\n",
    "    folder = Path(folder_path)\n",
    "    \n",
    "    # Get all .jpg files\n",
    "    jpg_files = sorted(folder.glob('*.jpg'))\n",
    "    \n",
    "    if not jpg_files:\n",
    "        print(f\"No .jpg files found in {folder_path}\")\n",
    "        return\n",
    "    \n",
    "    # Determine the number of digits needed for zero-padding\n",
    "    num_digits = len(str(len(jpg_files)))\n",
    "    num_digits = max(num_digits, 4)  # Use at least 4 digits\n",
    "    \n",
    "    \n",
    "    # Create temporary names first to avoid conflicts\n",
    "    temp_mapping = []\n",
    "    for i, old_path in enumerate(jpg_files, start=1):\n",
    "        temp_name = folder / f\"temp_{i}_{old_path.name}\"\n",
    "        old_path.rename(temp_name)\n",
    "        temp_mapping.append((temp_name, i))\n",
    "    \n",
    "    # Now rename to final names\n",
    "    for temp_path, i in temp_mapping:\n",
    "        new_name = f\"{prefix}_{str(i).zfill(num_digits)}.jpg\"\n",
    "        new_path = folder / new_name\n",
    "        temp_path.rename(new_path)\n",
    "        print(f\"  {temp_path.name} -> {new_name}\")\n",
    "    \n",
    "\n",
    "# Define paths\n",
    "train_dir = 'dataset/train'\n",
    "val_dir = 'dataset/val'\n",
    "\n",
    "# Rename images in train folder\n",
    "rename_images_in_folder(train_dir, 'train_img')\n",
    "\n",
    "# Rename images in validation folder\n",
    "rename_images_in_folder(val_dir, 'val_img')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
